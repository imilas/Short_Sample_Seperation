{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.initializers import glorot_uniform  # Or your initializer of choice\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import random\n",
    "import mir_utils as miru\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "input_dim=20000\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 1000  #floats -> compression factor of input_dim/encoding_dim\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(input_dim,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: /home/amir/mir/t-sne/samples\n",
      "loading: /home/amir/mir/t-sne/samples/claps\n",
      "loading: /home/amir/mir/t-sne/samples/snares\n",
      "loading: /home/amir/mir/t-sne/samples/kicks\n",
      "loading: /home/amir/mir/t-sne/samples/rims\n",
      "loading: /home/amir/mir/t-sne/samples/sines\n",
      "train,test shapes: (28, 10000) (4, 10000)\n",
      "(20000, 1000)\n",
      "(1000,)\n",
      "(1000, 20000)\n",
      "(20000,)\n",
      "[None, 20000]\n",
      "[None, 1000]\n",
      "[None, 20000]\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 20000)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1000)              20001000  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20000)             20020000  \n",
      "=================================================================\n",
      "Total params: 40,021,000\n",
      "Trainable params: 40,021,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# x_train = x_train.astype('float32') / 255.\n",
    "# x_test = x_test.astype('float32') / 255.\n",
    "# x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "# x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "a=miru.loadAudioSubset(20)\n",
    "#takes an audio dict, desired length of samples and split percentage of test & train subsets\n",
    "#returns x_train,x_test,y_train,y_test\n",
    "def audioDictToNp(a,dur=10000,testFraction=0):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for key,l in a.items():\n",
    "            for i in l:\n",
    "                if len(i)>dur:\n",
    "                    y.append(key)\n",
    "                    X.append(i[0:dur])\n",
    "    X=np.asarray(X)\n",
    "    y=np.asarray(y)\n",
    "    if testFraction==0:\n",
    "        return X,y,X,y\n",
    "    else:\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testFraction, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "            \n",
    "x_train, x_test, y_train, y_test=audioDictToNp(a,testFraction=0.1)\n",
    "\n",
    "print(\"train,test shapes:\",x_train.shape,x_test.shape)\n",
    "Wsave = autoencoder.get_weights()\n",
    "for a in Wsave:\n",
    "    print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio test to see if array works\n",
    "import sounddevice as sd\n",
    "sd.play(x_train[9],40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 10000)\n",
      "(4, 10000)\n",
      "(20000, 1000)\n",
      "(1000,)\n",
      "(1000, 20000)\n",
      "(20000,)\n",
      "[None, 20000]\n",
      "[None, 1000]\n",
      "[None, 20000]\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 20000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              20001000  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20000)             20020000  \n",
      "=================================================================\n",
      "Total params: 40,021,000\n",
      "Trainable params: 40,021,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (x_train.shape)\n",
    "print (x_test.shape)\n",
    "\n",
    "Wsave = autoencoder.get_weights()\n",
    "for a in Wsave:\n",
    "    print(a.shape)\n",
    "for layer in autoencoder.layers:\n",
    "     print(layer.get_output_at(0).get_shape().as_list())\n",
    "\n",
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train=x_train[0:50]\n",
    "x_test=x_train[0:10]\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)\n",
    "def train():\n",
    "    initial_weights = autoencoder.get_weights()\n",
    "    weights = [glorot_uniform(seed=random.randint(0, 1000))(w.shape) if w.ndim > 1 else w for w in autoencoder.get_weights()]\n",
    "    autoencoder.set_weights(new_weights)\n",
    "\n",
    "    autoencoder.fit(x_train, x_train,\n",
    "                    epochs=1000,\n",
    "                    batch_size=10,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test, x_test),\n",
    "                    verbose=1,\n",
    "                    callbacks=[TensorBoard(log_dir='/tmp/autoencoder')]\n",
    "                   )\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_train[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "89aaa044-9b66-402c-83c7-889f88e4f2f0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
